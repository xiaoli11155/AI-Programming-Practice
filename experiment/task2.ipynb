{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a361a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f3be43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "class RandomColorize(object):\n",
    "    \"\"\"Custom transform to randomize background and font colors\"\"\"\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            # Convert to grayscale first\n",
    "            img = ImageOps.grayscale(img)\n",
    "            \n",
    "            # Random background color (RGB)\n",
    "            bg_color = (random.randint(0, 255), \n",
    "                       random.randint(0, 255), \n",
    "                       random.randint(0, 255))\n",
    "            \n",
    "            # Random font color (RGB), different from background\n",
    "            font_color = (random.randint(0, 255), \n",
    "                         random.randint(0, 255), \n",
    "                         random.randint(0, 255))\n",
    "            while font_color == bg_color:  # Ensure they're different\n",
    "                font_color = (random.randint(0, 255), \n",
    "                             random.randint(0, 255), \n",
    "                             random.randint(0, 255))\n",
    "            \n",
    "            # Convert grayscale to RGB\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Replace black (font) and white (background) with new colors\n",
    "            data = np.array(img)\n",
    "            red, green, blue = data[:,:,0], data[:,:,1], data[:,:,2]\n",
    "            \n",
    "            # Create masks\n",
    "            font_mask = (red < 128) | (green < 128) | (blue < 128)\n",
    "            bg_mask = ~font_mask\n",
    "            \n",
    "            # Apply new colors\n",
    "            data[:,:,:3][font_mask] = font_color\n",
    "            data[:,:,:3][bg_mask] = bg_color\n",
    "            \n",
    "            img = Image.fromarray(data)\n",
    "            \n",
    "        return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c240ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class AdvancedAugmentation:\n",
    "    \"\"\"自定义高级数据增强组合\"\"\"\n",
    "    def __init__(self, image_size=28):  # Changed default to 28 to match your transforms\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.Resize(28),\n",
    "            transforms.CenterCrop(28),\n",
    "            RandomColorize(p=0.5),  # Added color randomization\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            transforms.RandomAffine(degrees=20, shear=10, scale=(0.9, 1.1)),\n",
    "            transforms.GaussianBlur(kernel_size=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            transforms.RandomErasing(p=0.5, scale=(0.02, 0.2), ratio=(0.3, 3.3)),\n",
    "        ])\n",
    "\n",
    "        self.val_transform = transforms.Compose([\n",
    "            transforms.Resize(28),\n",
    "            transforms.CenterCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        \n",
    "class CustomDataset(Dataset):\n",
    "    \"\"\"支持缓存、增强、.pt文件的自定义数据集\"\"\"\n",
    "    def __init__(self, pt_file, transform=None, cache=True):\n",
    "        self.data_label_tuples = torch.load(pt_file)\n",
    "        self.transform = transform\n",
    "        self.cache = cache\n",
    "        self.cached_data = {}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_label_tuples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx in self.cached_data and self.cache:\n",
    "            return self.cached_data[idx]\n",
    "        \n",
    "        img, label = self.data_label_tuples[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        if self.cache:\n",
    "            self.cached_data[idx] = (img, label)\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "def get_dataloaders(data_dir, train_env='train1', val_env='test1',\n",
    "                    batch_size=32, image_size=224, num_workers=4, pin_memory=True):\n",
    "    \"\"\"\n",
    "    加载 ColoredMNIST .pt 数据，并应用增强\n",
    "    \"\"\"\n",
    "    aug = AdvancedAugmentation(image_size)\n",
    "    \n",
    "    train_dataset = CustomDataset(\n",
    "        pt_file=os.path.join(data_dir, f\"{train_env}.pt\"),\n",
    "        transform=aug.train_transform,\n",
    "        cache=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = CustomDataset(\n",
    "        pt_file=os.path.join(data_dir, f\"{val_env}.pt\"),\n",
    "        transform=aug.val_transform,\n",
    "        cache=False\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory,\n",
    "        drop_last=True,\n",
    "        persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=pin_memory\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99a451d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "class RandomColorize(object):\n",
    "    \"\"\"独立定义的颜色随机化变换\"\"\"\n",
    "    def __init__(self, p=0.5):\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            img = ImageOps.grayscale(img)\n",
    "            bg_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            font_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            while font_color == bg_color:\n",
    "                font_color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "            \n",
    "            img = img.convert(\"RGB\")\n",
    "            data = np.array(img)\n",
    "            red, green, blue = data[:,:,0], data[:,:,1], data[:,:,2]\n",
    "            font_mask = (red < 128) | (green < 128) | (blue < 128)\n",
    "            bg_mask = ~font_mask\n",
    "            data[:,:,:3][font_mask] = font_color\n",
    "            data[:,:,:3][bg_mask] = bg_color\n",
    "            img = Image.fromarray(data)\n",
    "        return img\n",
    "\n",
    "def visualize_augmentations(tensor_data, transform, num_samples=10):\n",
    "    \"\"\"独立可视化函数\"\"\"\n",
    "    num_samples = min(num_samples, len(tensor_data))\n",
    "    samples = tensor_data[:num_samples]\n",
    "    \n",
    "    # 应用变换\n",
    "    augmented_samples = [transform(img) for img in samples]\n",
    "    \n",
    "    # 反归一化\n",
    "    def denormalize(tensor):\n",
    "        mean = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.5, 0.5, 0.5]).view(3, 1, 1)\n",
    "        return tensor * std + mean\n",
    "    \n",
    "    # 准备显示\n",
    "    grid_original = make_grid(samples, nrow=num_samples)\n",
    "    grid_augmented = make_grid([denormalize(img) for img in augmented_samples], nrow=num_samples)\n",
    "    \n",
    "    # 显示\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(grid_original.permute(1, 2, 0).clamp(0, 1))\n",
    "    plt.title(\"Original\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(grid_augmented.permute(1, 2, 0).clamp(0, 1))\n",
    "    plt.title(\"Augmented\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e616c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5, 1, 2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5, 1, 0),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16 * 5 * 5, 120),  \n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(84, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e003611",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_model(data_dir, train_env, epochs=10, batch_size=32, learning_rate=0.01, image_size=224):\n",
    "    print(f\"Loading training data from: {train_env}\")\n",
    "    \n",
    "    train_loader, _ = get_dataloaders(\n",
    "        data_dir=data_dir,\n",
    "        train_env=train_env,\n",
    "        val_env='test1',  # 这里val_env其实无所谓，反正你只用train_loader\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    model = LeNet().to(device)\n",
    "    loss_function = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            total_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / total_samples\n",
    "        epoch_acc = total_correct / total_samples\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4ef91ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, data_dir, test_env, batch_size=1000, image_size=224):\n",
    "    print(f\"Testing on dataset: {test_env}\")\n",
    "    \n",
    "    _, val_loader = get_dataloaders(\n",
    "        data_dir=data_dir,\n",
    "        train_env='train1',  # 随便占位一下\n",
    "        val_env=test_env,\n",
    "        batch_size=batch_size,\n",
    "        image_size=image_size,\n",
    "        num_workers=4\n",
    "    )\n",
    "    \n",
    "    model.eval()\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            total_correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            total_samples += inputs.size(0)\n",
    "\n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a39309bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training model on train1\n",
      "Loading training data from: train1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4045/2944689738.py:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data_label_tuples = torch.load(pt_file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6938, Accuracy: 0.5077\n",
      "Epoch 2/10 - Loss: 0.6932, Accuracy: 0.5059\n",
      "Epoch 3/10 - Loss: 0.6929, Accuracy: 0.5144\n",
      "Epoch 4/10 - Loss: 0.6935, Accuracy: 0.4997\n",
      "Epoch 5/10 - Loss: 0.6932, Accuracy: 0.5130\n",
      "Epoch 6/10 - Loss: 0.6935, Accuracy: 0.5053\n",
      "Epoch 7/10 - Loss: 0.6934, Accuracy: 0.5032\n",
      "Epoch 8/10 - Loss: 0.6932, Accuracy: 0.5147\n",
      "Epoch 9/10 - Loss: 0.6933, Accuracy: 0.5063\n",
      "Epoch 10/10 - Loss: 0.6933, Accuracy: 0.5069\n",
      "Testing on dataset: test1\n",
      "Test accuracy: 0.5074\n",
      "Testing on dataset: test2\n",
      "Test accuracy: 0.5103\n",
      "==================================================\n",
      "Training model on train2\n",
      "Loading training data from: train2\n",
      "Epoch 1/10 - Loss: 0.6942, Accuracy: 0.5027\n",
      "Epoch 2/10 - Loss: 0.6933, Accuracy: 0.5082\n",
      "Epoch 3/10 - Loss: 0.6937, Accuracy: 0.5046\n",
      "Epoch 4/10 - Loss: 0.6934, Accuracy: 0.4994\n",
      "Epoch 5/10 - Loss: 0.6935, Accuracy: 0.5010\n",
      "Epoch 6/10 - Loss: 0.6934, Accuracy: 0.5000\n",
      "Epoch 7/10 - Loss: 0.6933, Accuracy: 0.5025\n",
      "Epoch 8/10 - Loss: 0.6939, Accuracy: 0.5018\n",
      "Epoch 9/10 - Loss: 0.6933, Accuracy: 0.5068\n",
      "Epoch 10/10 - Loss: 0.6936, Accuracy: 0.5017\n",
      "Testing on dataset: test1\n",
      "Test accuracy: 0.5074\n",
      "Testing on dataset: test2\n",
      "Test accuracy: 0.5103\n",
      "==================================================\n",
      "Training model on train3\n",
      "Loading training data from: train3\n",
      "Epoch 1/10 - Loss: 0.5721, Accuracy: 0.6604\n",
      "Epoch 2/10 - Loss: 0.4815, Accuracy: 0.7302\n",
      "Epoch 3/10 - Loss: 0.4458, Accuracy: 0.7492\n",
      "Epoch 4/10 - Loss: 0.4273, Accuracy: 0.7670\n",
      "Epoch 5/10 - Loss: 0.3959, Accuracy: 0.7914\n",
      "Epoch 6/10 - Loss: 0.3972, Accuracy: 0.7783\n",
      "Epoch 7/10 - Loss: 0.3866, Accuracy: 0.7947\n",
      "Epoch 8/10 - Loss: 0.3703, Accuracy: 0.8046\n",
      "Epoch 9/10 - Loss: 0.3707, Accuracy: 0.8054\n",
      "Epoch 10/10 - Loss: 0.3611, Accuracy: 0.8103\n",
      "Testing on dataset: test1\n",
      "Test accuracy: 0.7253\n",
      "Testing on dataset: test2\n",
      "Test accuracy: 0.4978\n",
      "\n",
      "All results:\n",
      "Model trained on train1:\n",
      "  Test on test1: Accuracy = 0.5074\n",
      "  Test on test2: Accuracy = 0.5103\n",
      "Model trained on train2:\n",
      "  Test on test1: Accuracy = 0.5074\n",
      "  Test on test2: Accuracy = 0.5103\n",
      "Model trained on train3:\n",
      "  Test on test1: Accuracy = 0.7253\n",
      "  Test on test2: Accuracy = 0.4978\n"
     ]
    }
   ],
   "source": [
    "train_envs = ['train1', 'train2', 'train3']\n",
    "test_envs = ['test1', 'test2']\n",
    "\n",
    "results = {}\n",
    "\n",
    "for train_env in train_envs:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Training model on {train_env}\")\n",
    "    model = train_one_model('./data/ColoredMNIST', train_env, epochs=10)\n",
    "\n",
    "    # 测试模型在两个测试集上的表现\n",
    "    accuracies = {}\n",
    "    for test_env in test_envs:\n",
    "        acc = test_model(model, './data/ColoredMNIST', test_env)\n",
    "        accuracies[test_env] = acc\n",
    "    results[train_env] = accuracies\n",
    "\n",
    "# 输出全部结果\n",
    "print(\"\\nAll results:\")\n",
    "for train_set, test_accs in results.items():\n",
    "    print(f\"Model trained on {train_set}:\")\n",
    "    for test_set, acc in test_accs.items():\n",
    "        print(f\"  Test on {test_set}: Accuracy = {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
